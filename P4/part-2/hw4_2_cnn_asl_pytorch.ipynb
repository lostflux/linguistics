{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iTgWVTbO3B1"
   },
   "source": [
    "# Homework 4.2: Convolutional Neural Networks and ASL\n",
    "Dartmouth College, LING48/CS72, Winter 2024<br>\n",
    "Kenneth Lai (Kenneth.Han.Lai@dartmouth.edu)\n",
    "\n",
    "A convolutional neural network (ConvNet/CNN) is optimized to understand visual data.\n",
    "This code in particular comes from this URL:\n",
    "https://github.com/samurainote/CNN_for_Sign_Language_Images/blob/master/CNN_for_Sign_Language_Images.ipynb\n",
    "Code converted to PyTorch by Colin Kearns (Colin.R.Kearns.25@dartmouth.edu)\n",
    "\n",
    "In this program, we used a CNN to learn 6 signs from ASL finger spelling (a way to import words from other languages, such as English). The training set has information for approximately 1100 different pictures for each sign. The information is presented as the black-and-white pixel values for 784 pixels (28*28). The training set also contains the gold labels for each picture (a=0, b=1, c=2, d=3, e=4, f=5). The testing set has information\n",
    "for 2063 pictures for each ASL sign. (331 'a', 432 'b', 310 'c', 245 'd', 498 'e' and 247 'f'. It uses the same format as the training set. The original information (with pictures for all the ASL signs) comes from here: https://www.kaggle.com/datamunge/sign-language-mnist\n",
    "\n",
    "There are many good sites where you can learn the intuitions behind convolutional networks. These are some examples:\n",
    "\n",
    "(1) https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/<br>\n",
    "(2) https://www.youtube.com/watch?v=iaSUYvmCekI<br>\n",
    "(3) https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/<br>\n",
    "(4) https://www.freecodecamp.org/news/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050/\n",
    "\n",
    "Similarly to part 1, you will build a basic CNN, by filling in the `__init__` and `forward` functions in the `Model` class, as well as the training loop. Please build the CNN as follows:\n",
    "\n",
    "- Three convolution “blocks”. Each block should contain:\n",
    " - A 2D convolution layer\n",
    " - A ReLU activation function\n",
    " - A 2D max pooling layer\n",
    "\n",
    "  Because the images are grayscale, the first convolution layer has 1 input channel (if they were color, we would have 3 input channels). The first convolution layer should have 32 output channels, and the second and third should have 64 output channels. Each convolution layer should use a kernel size of (3, 3) and a stride length of 1, while each max pooling layer should use a kernel size of (2, 2) and a stride length of 2.\n",
    "\n",
    "\n",
    "- A “flatten” layer (to turn 2D images into vectors)\n",
    "- A hidden Linear layer with 128 neurons\n",
    "- A ReLU activation function\n",
    "- An output Linear layer with `classes` neurons\n",
    "\n",
    "Note that you should be able to reuse the training loop you wrote for part 1. As such, it will only be graded once (in part 1).\n",
    "\n",
    "Then, you need to write answers to these two questions:\n",
    "\n",
    "1. Study the links above and explain the structure of the CNN in your own words. What is a kernel? What is pooling? Explain all of these as simply and plainly as you can. Your answer should include how the size of the image changes as it passes through the convolution blocks.\n",
    "\n",
    "\n",
    "2. Run the program. How is the network behaving after one epoch of training? (Report this based on the accuracy, the precision, and the recall for each of the letters). Include screenshots of your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lDk0g5kQGDOZ"
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IJTj6kVAGKyx"
   },
   "outputs": [],
   "source": [
    "# Load ASL data\n",
    "\n",
    "train = pd.read_csv(\"sign-train-a-f.csv\")\n",
    "test = pd.read_csv(\"sign-test-a-f.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UW_YH9oWG-6o"
   },
   "outputs": [],
   "source": [
    "# Split the samples into a training and a test set\n",
    "\n",
    "totalSamplesTraining = len(train)\n",
    "totalSamplesTesting  = len(test)\n",
    "\n",
    "train_T = train[\"label\"]\n",
    "train.drop(\"label\", axis=1, inplace=True)\n",
    "\n",
    "test_T = test[\"label\"]\n",
    "test.drop(\"label\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QgogYM18HFWo"
   },
   "outputs": [],
   "source": [
    "# Define the PyTorch model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Add the layers and activation functions here\n",
    "        self.layers = nn.Sequential(\n",
    "            \n",
    "            #? first convolutional layer\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            #? second convolutional layer\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            #? third convolutional layer\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            #? flatten the output\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            #? 128-neurons linear layer\n",
    "            nn.Linear(64, 128),\n",
    "            \n",
    "            #? relu activation\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #? output layer with <classes> neurons\n",
    "            nn.Linear(128, classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass here\n",
    "        y = self.layers(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OK5l5uiXHJMo"
   },
   "outputs": [],
   "source": [
    "# Initialize the PyTorch model\n",
    "classes = len(train_T.unique()) # Specify the value of classes\n",
    "pytorch_model = CNNModel(classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pytorch_model.parameters())\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(train.values, dtype=torch.float32).view(totalSamplesTraining, 1, 28, 28)\n",
    "y_train_tensor = torch.tensor(train_T, dtype=torch.long)\n",
    "\n",
    "x_test_tensor = torch.tensor(test.values, dtype=torch.float32).view(totalSamplesTesting, 1, 28, 28)\n",
    "y_test_tensor = torch.tensor(test_T, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for training and testing data\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# Batch size for training and testing\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "oUQKjY_DF9Bv",
    "outputId": "d6d59f6e-b29a-4bbb-e669-4c64f6163591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.0124\n",
      "Test Loss: 0.07614024728536606, Test Accuracy: 0.979641318321228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       331\n",
      "           1       1.00      1.00      1.00       432\n",
      "           2       1.00      1.00      1.00       310\n",
      "           3       1.00      0.92      0.96       245\n",
      "           4       0.92      1.00      0.96       498\n",
      "           5       1.00      1.00      1.00       247\n",
      "\n",
      "    accuracy                           0.98      2063\n",
      "   macro avg       0.99      0.98      0.98      2063\n",
      "weighted avg       0.98      0.98      0.98      2063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        #? Forward pass\n",
    "        outputs = pytorch_model(inputs)\n",
    "        \n",
    "        #? Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #? Reset the gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #? Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        #? Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation on test set\n",
    "pytorch_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = pytorch_model(x_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "    _, test_preds = torch.max(test_outputs, 1)\n",
    "    accuracy = (test_preds == y_test_tensor).float().mean()\n",
    "\n",
    "    print(f\"Test Loss: {test_loss.item()}, Test Accuracy: {accuracy.item()}\")\n",
    "\n",
    "# Convert predictions to numpy arrays for classification report\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "test_preds_np = test_preds.numpy()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_np, test_preds_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "myb0YO5mjkhd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[309   0   0   0  22   0]\n",
      " [  0 431   0   0   0   1]\n",
      " [  0   0 310   0   0   0]\n",
      " [  0   0   0 226  19   0]\n",
      " [  0   0   0   0 498   0]\n",
      " [  0   0   0   0   0 247]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_np, test_preds_np))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
