{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfXr-CmLZWTa"
   },
   "source": [
    "# Homework 4.1: Neural Network for Cook Islands Māori Parts of Speech\n",
    "Dartmouth College, LING48/CS72, Winter 2024<br>\n",
    "Kenneth Lai (Kenneth.Han.Lai@dartmouth.edu)\n",
    "\n",
    "Code modified from:\n",
    "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/<br>\n",
    "Code converted to PyTorch by Colin Kearns (Colin.R.Kearns.25@dartmouth.edu)\n",
    "\n",
    "Before you start writing any code, you should first read the starter code and understand what it is doing. Then, in block 5, you will fill in the `__init__` and `forward` functions in the `Model` class, as well as the training loop:\n",
    "\n",
    "- `__init__(self, input_dims)`: This function defines the structure of the neural network. Please build the network as follows:\n",
    " - A hidden Linear layer with 48 neurons\n",
    " - A ReLU activation function\n",
    " - A hidden Linear layer with 24 neurons\n",
    " - A ReLU activation function\n",
    " - An output Linear layer with 3 neurons (i.e., the number of output classes)\n",
    "\n",
    "  Note that in PyTorch, the activation functions are separate from the layers, which just compute the “score” z=xW+b. Also note that there is no activation function after the output layer. While one would expect there to be a softmax function here, the `criterion` (loss function) `nn.CrossEntropyLoss()` includes the softmax function already, so we don’t need to include it here.\n",
    "\n",
    "\n",
    "- forward(self, x): This function defines the forward pass. Here, you will pass the input `x` through each of the layers and activation functions defined in `__init__`, in sequence.\n",
    "\n",
    "\n",
    "- Training loop: Finally, in the training loop, you will do five things (in one line of code each):\n",
    "\n",
    " 1. Run the forward pass: pass the `inputs` through the `pytorch_model`.\n",
    " 2. Compute the loss (for the current mini-batch).\n",
    " 3. Reset the gradient to zero (otherwise we will keep adding to the gradient already there).\n",
    " 4. Run the backward pass.\n",
    " 5. Update the parameters.\n",
    "\n",
    "Run the program three times and record the training and test accuracy for each of the three runs. What is the average training accuracy? What is the average accuracy for the test set? How are the F1-scores behaving? (You can see more information on how the predictions are working by looking at the predictions for the first fifteen items.) Write these answers in a PDF file. Include screenshots of your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "s3S3JYLuJNee"
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3x1_Z5D0JiNP"
   },
   "outputs": [],
   "source": [
    "# Load file and split into training data (nX) and the labels we are trying to predict (ny)\n",
    "\n",
    "cimData = pd.read_csv(\"cim-3pos.csv\")\n",
    "dataset = cimData\n",
    "nX = cimData.drop('tokenPOS', axis=1)\n",
    "ny = cimData['tokenPOS']\n",
    "\n",
    "numberValidPOS = 3  # noun, verb, preposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpL1ZGCYJo_-",
    "outputId": "cf8a1bd5-1e47-4264-9339-4f8f5fc5a214"
   },
   "outputs": [],
   "source": [
    "# Encode the words into numbers and then split the data randomly into training and test sets.\n",
    "\n",
    "encoderX = OneHotEncoder(sparse_output=True)\n",
    "X = encoderX.fit_transform(nX)\n",
    "encoderY = LabelEncoder()\n",
    "y = encoderY.fit_transform(ny)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10)\n",
    "\n",
    "inputDims = 1497 # the total of features in the OneHotEncoded X vector (total number of unique words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9gAOKT5Mlj2",
    "outputId": "c988b001-e64a-4188-d025-b9c950c4be6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training data, predictive features, first row ---\n",
      "[['tei' 'roto' 'te']]\n",
      "\n",
      "--- Training data, predicted result, first row ---\n",
      "['n']\n",
      "\n",
      "--- Training data, predictive features, first row, one-hot encoded ---\n",
      "  (0, 341)\t1.0\n",
      "  (0, 950)\t1.0\n",
      "  (0, 1440)\t1.0\n",
      "\n",
      "--- Training data, predicted result, first row, one-hot encoded ---\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Here, you can study what the dataset looks like (as text and encoded)\n",
    "\n",
    "print(\"--- Training data, predictive features, first row ---\")\n",
    "print(encoderX.inverse_transform(X_train[0:1]))\n",
    "print(\"\\n--- Training data, predicted result, first row ---\")\n",
    "print(encoderY.inverse_transform(y_train[0:1]))\n",
    "print(\"\\n--- Training data, predictive features, first row, one-hot encoded ---\")\n",
    "print(X_train[0:1])\n",
    "print(\"\\n--- Training data, predicted result, first row, one-hot encoded ---\")\n",
    "print(y_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jCykZfQJuI-",
    "outputId": "4de19d56-22d2-446f-beb9-c76617ecf2ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.7920\n",
      "Epoch [2/50], Loss: 0.4093\n",
      "Epoch [3/50], Loss: 0.1764\n",
      "Epoch [4/50], Loss: 0.0462\n",
      "Epoch [5/50], Loss: 0.0106\n",
      "Epoch [6/50], Loss: 0.0722\n",
      "Epoch [7/50], Loss: 0.0197\n",
      "Epoch [8/50], Loss: 0.0088\n",
      "Epoch [9/50], Loss: 0.0099\n",
      "Epoch [10/50], Loss: 0.0152\n",
      "Epoch [11/50], Loss: 0.0047\n",
      "Epoch [12/50], Loss: 0.0006\n",
      "Epoch [13/50], Loss: 0.0017\n",
      "Epoch [14/50], Loss: 0.0015\n",
      "Epoch [15/50], Loss: 0.0026\n",
      "Epoch [16/50], Loss: 0.0130\n",
      "Epoch [17/50], Loss: 0.0017\n",
      "Epoch [18/50], Loss: 0.0012\n",
      "Epoch [19/50], Loss: 0.0049\n",
      "Epoch [20/50], Loss: 0.0760\n",
      "Epoch [21/50], Loss: 0.0020\n",
      "Epoch [22/50], Loss: 0.0003\n",
      "Epoch [23/50], Loss: 0.0000\n",
      "Epoch [24/50], Loss: 0.0001\n",
      "Epoch [25/50], Loss: 0.0006\n",
      "Epoch [26/50], Loss: 0.0003\n",
      "Epoch [27/50], Loss: 0.0003\n",
      "Epoch [28/50], Loss: 0.0007\n",
      "Epoch [29/50], Loss: 0.0001\n",
      "Epoch [30/50], Loss: 0.0002\n",
      "Epoch [31/50], Loss: 0.0003\n",
      "Epoch [32/50], Loss: 0.0000\n",
      "Epoch [33/50], Loss: 0.0004\n",
      "Epoch [34/50], Loss: 0.0001\n",
      "Epoch [35/50], Loss: 0.0002\n",
      "Epoch [36/50], Loss: 0.0046\n",
      "Epoch [37/50], Loss: 0.0002\n",
      "Epoch [38/50], Loss: 0.0002\n",
      "Epoch [39/50], Loss: 0.0110\n",
      "Epoch [40/50], Loss: 0.0000\n",
      "Epoch [41/50], Loss: 0.0042\n",
      "Epoch [42/50], Loss: 0.0001\n",
      "Epoch [43/50], Loss: 0.0004\n",
      "Epoch [44/50], Loss: 0.0006\n",
      "Epoch [45/50], Loss: 0.0011\n",
      "Epoch [46/50], Loss: 0.0004\n",
      "Epoch [47/50], Loss: 0.0001\n",
      "Epoch [48/50], Loss: 0.0001\n",
      "Epoch [49/50], Loss: 0.0001\n",
      "Epoch [50/50], Loss: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse array to dense tensor\n",
    "X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "# Define the PyTorch model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dims):\n",
    "        super(Model, self).__init__()\n",
    "        # Add the layers and activation functions here\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dims, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass here\n",
    "        \n",
    "        #? step through the layers\n",
    "        y = self.layers(x)\n",
    "        \n",
    "        return y\n",
    "\n",
    "# Initialize the PyTorch model\n",
    "inputDims = 1497 # Specify the value of inputDims\n",
    "pytorch_model = Model(inputDims)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pytorch_model.parameters())\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        #? Forward pass\n",
    "        outputs = pytorch_model(inputs)\n",
    "        \n",
    "        #? Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #? Reset the gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #? Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        #? Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvzIMsplJDWs",
    "outputId": "0a3555c9-7b66-41ff-a535-b624467f3701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Results from final layer of the first 5 items in test set =====\n",
      "1: 0\n",
      "2: 2\n",
      "3: 0\n",
      "4: 1\n",
      "5: 0\n",
      "\n",
      "===== Size of test set =====\n",
      "258\n",
      "\n",
      "===== Test data, predictive features, first 15 rows =====\n",
      "[['kua' 'qox' 'ake']\n",
      " ['i' 'kai' 'i']\n",
      " ['au' 'ariki' 'rava']\n",
      " ['reira' 'i' 'a']\n",
      " ['te' 'qenua' 'ki']\n",
      " ['ko' 'qangaqanga' 'mua']\n",
      " ['tei' 'piri' 'mai']\n",
      " ['mea' 'tamaiti' 'varevare']\n",
      " ['ko' 'pae' 'ra']\n",
      " ['e' 'ngatax' 'ana']\n",
      " ['e' 'kai' 'ana']\n",
      " ['kax' 'pexti' '-']\n",
      " ['te' 'tipunu' '-']\n",
      " ['ex' 'tei' 'roto']\n",
      " ['te' 'maxtipi' '-']]\n",
      "\n",
      "===== Test data, predicted result, first 15 rows =====\n",
      "[0, 2, 0, 1, 0, 0, 2, 0, 0, 2, 2, 2, 0, 1, 2]\n",
      "\n",
      "===== Test data, expected result, first 15 rows =====\n",
      "['v' 'v' 'n' 'prep' 'n' 'n' 'v' 'n' 'n' 'v' 'n' 'v' 'n' 'prep' 'n']\n",
      "\n",
      "===== Accuracy of test set =====\n",
      "93.0%\n",
      "\n",
      "===== Predictions =====\n",
      "item 01: Predicted: 0 / ['n']  \tActual value: 2 / ['v'] \t\n",
      "item 02: Predicted: 2 / ['v']  \tActual value: 2 / ['v'] \t*Correct!*\n",
      "item 03: Predicted: 0 / ['n']  \tActual value: 0 / ['n'] \t*Correct!*\n",
      "item 04: Predicted: 1 / ['prep']  \tActual value: 1 / ['prep'] \t*Correct!*\n",
      "item 05: Predicted: 0 / ['n']  \tActual value: 0 / ['n'] \t*Correct!*\n",
      "item 06: Predicted: 0 / ['n']  \tActual value: 0 / ['n'] \t*Correct!*\n",
      "item 07: Predicted: 2 / ['v']  \tActual value: 2 / ['v'] \t*Correct!*\n",
      "item 08: Predicted: 0 / ['n']  \tActual value: 0 / ['n'] \t*Correct!*\n",
      "item 09: Predicted: 0 / ['n']  \tActual value: 0 / ['n'] \t*Correct!*\n",
      "item 10: Predicted: 2 / ['v']  \tActual value: 2 / ['v'] \t*Correct!*\n",
      "item 11: Predicted: 2 / ['v']  \tActual value: 0 / ['n'] \t\n",
      "item 12: Predicted: 2 / ['v']  \tActual value: 2 / ['v'] \t*Correct!*\n",
      "item 13: Predicted: 0 / ['n']  \tActual value: 0 / ['n'] \t*Correct!*\n",
      "item 14: Predicted: 1 / ['prep']  \tActual value: 1 / ['prep'] \t*Correct!*\n",
      "item 15: Predicted: 2 / ['v']  \tActual value: 0 / ['n'] \t\n"
     ]
    }
   ],
   "source": [
    "# Convert test data to PyTorch tensor\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "\n",
    "# Make class predictions with the model\n",
    "print(\"===== Results from final layer of the first 5 items in test set =====\")\n",
    "with torch.no_grad():\n",
    "    t = pytorch_model(X_test_tensor[:5])\n",
    "    predictions = torch.argmax(t, dim=1).numpy()\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"{i + 1}: {predictions[i]}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "total_correct = 0\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(y_test)):\n",
    "        temp_pred = torch.argmax(pytorch_model(X_test_tensor[i]), dim=0).item()\n",
    "        if temp_pred < numberValidPOS:\n",
    "            predicted_labels.append(temp_pred)\n",
    "        else:\n",
    "            predicted_labels.append(0)\n",
    "\n",
    "        if predicted_labels[i] == y_test[i]:\n",
    "            total_correct += 1\n",
    "\n",
    "accuracy = round((total_correct / len(y_test)) * 100, 0)\n",
    "\n",
    "print(\"\\n===== Size of test set =====\")\n",
    "print(len(y_test))\n",
    "print(\"\\n===== Test data, predictive features, first 15 rows =====\")\n",
    "print(encoderX.inverse_transform(X_test[:15]))\n",
    "print(\"\\n===== Test data, predicted result, first 15 rows =====\")\n",
    "print(predicted_labels[:15])\n",
    "print(\"\\n===== Test data, expected result, first 15 rows =====\")\n",
    "print(encoderY.inverse_transform(y_test[:15]))\n",
    "print(\"\\n===== Accuracy of test set =====\")\n",
    "print(f\"{accuracy}%\")\n",
    "print(\"\\n===== Predictions =====\")\n",
    "\n",
    "is_it_correct = \"\"\n",
    "for i in range(15):\n",
    "    item_num = \"0\" + str(i + 1) if i < 9 else str(i + 1)\n",
    "\n",
    "    if predicted_labels[i] == y_test[i]:\n",
    "        is_it_correct = \"*Correct!*\"\n",
    "    else:\n",
    "        is_it_correct = \"\"\n",
    "\n",
    "    print(f\"item {item_num}: Predicted: {predicted_labels[i]} / {encoderY.inverse_transform([predicted_labels[i]])}  \\tActual value: {y_test[i]} / {encoderY.inverse_transform([y_test[i]])} \\t{is_it_correct}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXvmMu0uRiBD",
    "outputId": "3b3f3bda-21d2-40d0-f7e0-1381b7d6a10e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       115\n",
      "           1       0.99      1.00      0.99        79\n",
      "           2       0.87      0.84      0.86        64\n",
      "\n",
      "    accuracy                           0.93       258\n",
      "   macro avg       0.92      0.92      0.92       258\n",
      "weighted avg       0.93      0.93      0.93       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nijl0CEq3H8z",
    "outputId": "0dfbc909-de37-426b-9e1f-dee8220a0025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106   1   8]\n",
      " [  0  79   0]\n",
      " [ 10   0  54]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predicted_labels))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
